{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense,Embedding,LSTM,Input\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path='/home/al/Desktop/nnfl/pruned.word2vec.txt'\n",
    "data = np.loadtxt(ds_path,dtype=str,usecols=(0),skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,data.shape[0]):\n",
    "    data[i]=data[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix=dict(zip(data,range(0,data.shape[0])))\n",
    "ix_to_word=dict(zip(range(0,data.shape[0]),data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc=data.shape[0]+3\n",
    "data=np.delete(data,range(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 50, 64)            2814976   \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 50, 512)           1181696   \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 50, 512)           2099200   \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 50, 512)           2099200   \n_________________________________________________________________\nlstm_4 (LSTM)                (None, 50, 512)           2099200   \n_________________________________________________________________\ndense_1 (Dense)              (None, 50, 43984)         22563792  \n=================================================================\nTotal params: 32,858,064\nTrainable params: 32,858,064\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Embedding(voc,64,input_length=50),\n",
    "    LSTM(512,return_sequences=True),\n",
    "    LSTM(512,return_sequences=True),\n",
    "    LSTM(512,return_sequences=True),\n",
    "    LSTM(512,return_sequences=True),\n",
    "    Dense(voc,activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer=\"Adam\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"/home/al/Desktop/nnfl/weights.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path='/home/al/Desktop/nnflproj/nds/nds-a'\n",
    "\n",
    "for e  in 'a':\n",
    "#bcdefghi':\n",
    "    for f  in 'a':\n",
    "        #bcdefghijklmnopqrstuvwxyz':\n",
    "        ds = np.loadtxt(d_path+e+f+'.csv',delimiter='\\n',dtype='str')\n",
    "        Xtr=np.ndarray(shape=[60000,50],dtype=int)\n",
    "        \n",
    "        Xv=np.ndarray(shape=[20000,50],dtype=int)\n",
    "\n",
    "        Xt=np.ndarray(shape=[20000-100000+ds.shape[0],50],dtype=int)\n",
    "        #x=np.ndarray(shape=[500,50,data.shape[0]])\n",
    "        #x = tf.cast(x,dtype = tf.int32)\n",
    "        for j in range(0,60000):\n",
    "                #ds.shape[0]-(ds.shape[0]%1000)+1)\n",
    "                w1=np.array(ds[j].lower().split())\n",
    "                for i in range(0,50):    \n",
    "                    w=w1[i+1]\n",
    "                    if i==49:\n",
    "                        #w1_sum/=50\n",
    "                        Xtr[j,i]=voc-2#for<end>\n",
    "                        \n",
    "                        break\n",
    "                    if w=='<start>':\n",
    "                        continue\n",
    "                    if w=='<end>':\n",
    "                        while i<49:\n",
    "                            Xtr[j,i]=voc-3#padding\n",
    "                            i+=1\n",
    "                        Xtr[j,i]=voc-2#for<end>\n",
    "                        break\n",
    "                    try:                \n",
    "                        #w1_sum+=d2[word_to_ix[w]]\n",
    "                        \n",
    "                        Xtr[j,i]=word_to_ix[w]\n",
    "                    except KeyError:\n",
    "                        #deal with unknown words\n",
    "                        Xtr[j,i]=voc-1#for<unk>\n",
    "        for j in range(0,20000):\n",
    "            w1=np.array(ds[60000+j].lower().split())\n",
    "            for i in range(0,50):    \n",
    "                    w=w1[i+1]\n",
    "                    if i==49:\n",
    "                        #w1_sum/=50\n",
    "                        Xv[j,i]=voc-2#for<end>\n",
    "                        \n",
    "                        break\n",
    "                    if w=='<start>':\n",
    "                        continue\n",
    "                    if w=='<end>':\n",
    "                        while i<49:\n",
    "                            Xv[j,i]=voc-3\n",
    "                            i+=1\n",
    "                        Xv[j,i]=data.shape[0]+1#for<end>\n",
    "                        break\n",
    "                    try:                \n",
    "                        #w1_sum+=d2[word_to_ix[w]]\n",
    "                        \n",
    "                        Xv[j,i]=word_to_ix[w]\n",
    "                    except KeyError:\n",
    "                        #deal with unknown words\n",
    "                        Xv[j,i]=voc-1#for<unk>\n",
    "        for j in range(0,ds.shape[0]-80000):\n",
    "            w1=np.array(ds[80000+j].lower().split())\n",
    "            for i in range(0,50):    \n",
    "                    w=w1[i+1]\n",
    "                    if i==49:\n",
    "                        #w1_sum/=50\n",
    "                        Xt[j,i]=voc-2#for<end>\n",
    "                        \n",
    "                        break\n",
    "                    if w=='<start>':\n",
    "                        continue\n",
    "                    if w=='<end>':\n",
    "                        while i<49:\n",
    "                            Xt[j,i]=voc-3\n",
    "                            i+=1\n",
    "                        Xt[j,i]=voc-2#for<end>\n",
    "                        break\n",
    "                    try:                \n",
    "                        #w1_sum+=d2[word_to_ix[w]]\n",
    "                        \n",
    "                        Xt[j,i]=word_to_ix[w]\n",
    "                    except KeyError:\n",
    "                        #deal with unknown words\n",
    "                        Xt[j,i]=voc-1#for<unk>\n",
    "                    '''\n",
    "            for l in range (0,10):    \n",
    "                 X2=tf.cast(X[500*k+50*l+1:500*k+50*l+51,:],dtype=tf.int32)\n",
    "                 X2=tf.one_hot(X2,depth=data.shape[0]+2)\n",
    "                 x=X[500*k+50*l:500*k+50*l+50,:].swapaxes(0,1)\n",
    "                 \n",
    "                 c=model.train_on_batch(x,X2,)\n",
    "                                    \n",
    "                #x=np.append(x,tf.one_hot(X[j],data.shape[0]))\n",
    "                    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[16030 19746 11788 42376 40418 32325 43983 43981 43981 43981 43981 43981\n 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981\n 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981\n 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981 43981\n 43981 43982]\nthey\n<start> they d spot it at once . <end>\n(19816, 50)\n"
    }
   ],
   "source": [
    "print(Xt[0])\n",
    "print(ix_to_word[Xt[0][0]])\n",
    "print(ds[80000])\n",
    "print(Xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def oh(Xq):\n",
    "    Xoh=np.zeros([Xq.shape[0],50,voc])\n",
    "    for i in range(Xq.shape[0]):\n",
    "        for j in range(50):\n",
    "            Xoh[i,j,Xq[i,j]]=1\n",
    "    return Xoh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=np.delete(ds,range(ds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 64 samples, validate on 16 samples\nEpoch 1/1\n4/4 [==============================] - 44s 11s/step - loss: 1.0631 - accuracy: 0.8497 - val_loss: 0.4929 - val_accuracy: 3.2500\n\nEpoch 00001: val_accuracy improved from -inf to 3.25000, saving model to /home/al/Desktop/nnfl/weights-01-0.49.hdf5\n"
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/home/al/Desktop/nnfl/weights-{epoch:02d}-{val_loss:.2f}.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-db6e07b3956b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/home/al/Desktop/nnfl/weights-{epoch:02d}-{val_loss:.2f}.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "for kl in range(64,60000,64):\n",
    "    u=oh(Xtr[kl-63:kl+1])\n",
    "    u.swapaxes(1,2)\n",
    "    k=int(kl/4)\n",
    "    u2=oh(Xv[k-15:k+1])\n",
    "    u2.swapaxes(1,2)\n",
    "    model.fit(Xtr[kl-64:kl],u,epochs=1,steps_per_epoch=4,validation_data=(Xv[k-16:k],u2),validation_steps=4,callbacks=[checkpoint])\n",
    "    model.load_weights(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kl in range(64,20000,64):\n",
    "    u=oh(Xt[kl-63:kl+1])\n",
    "    u.swapaxes(1,2)\n",
    "    model.evaluate(Xt[kl-64:kl],u,epochs=1,steps_per_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit910a7e525ea849fca55756066482ff27",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}